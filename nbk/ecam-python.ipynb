{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "otu_data = pd.read_csv(\"../data/ecam-table-taxa.tsv\",\n",
    "                       header=1, sep='\\t')\n",
    "otu_data = otu_data.set_index('feature-id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.read_csv(\"../data/ecam-sample-metadata.tsv\", sep='\\t')\n",
    "meta_data = meta_data[1:]\n",
    "meta_data = meta_data.rename(columns={'#SampleID': 'Sample.ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANCOM imports\n",
    "import numpy as np\n",
    "from scipy.stats import norm, mannwhitneyu, kruskal\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols, mixedlm\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _outlier_check(x, out_cut):\n",
    "    # Fitting the mixture model using the algorithm of Peddada, S. Das, and JT Gene Hwang (2002)\n",
    "    mu1, mu2 = np.nanquantile(x, (0.25, 0.75))\n",
    "    sigma1 = mu2 - mu1\n",
    "    sigma2 = sigma1\n",
    "    pi = 0.75\n",
    "    n = len(x)\n",
    "    epsilon = 100\n",
    "    tol = 1e-5\n",
    "    score = pi * norm.pdf(x, mu1, sigma1) / \\\n",
    "        ((1 - pi) * norm.pdf(x, mu2, sigma2))\n",
    "    while epsilon > tol:\n",
    "        grp1_ind = score >= 1\n",
    "        not_grp1_ind = np.logical_not(grp1_ind)\n",
    "        mu1_new = x[grp1_ind].mean()\n",
    "        mu2_new = x[not_grp1_ind].mean()\n",
    "        sigma1_new = x[grp1_ind].std()\n",
    "        if np.isnan(sigma1_new):\n",
    "            sigma1_new = 0.\n",
    "        sigma2_new = x[not_grp1_ind].std()\n",
    "        if np.isnan(sigma2_new):\n",
    "            sigma2_new = 0.\n",
    "        pi_new = sum(grp1_ind) / n\n",
    "        \n",
    "        para = [mu1_new, mu2_new, sigma1_new, sigma2_new, pi_new]\n",
    "        if np.any(np.isnan(para)):\n",
    "            break\n",
    "        \n",
    "        if sigma1_new == 0.:\n",
    "            pdf1 = np.zeros_like(x)\n",
    "            pdf1[x == mu1_new] = np.inf\n",
    "        else:\n",
    "            pdf1 = norm.pdf(x, mu1_new, sigma1_new)\n",
    "        if sigma2_new == 0.:\n",
    "            pdf2 = np.zeros_like(x)\n",
    "            pdf2[x == mu2_new] = np.inf\n",
    "        else:\n",
    "            pdf2 = norm.pdf(x, mu2_new, sigma2_new)\n",
    "        score = pi_new * pdf1 / ((1 - pi_new) * pdf2)\n",
    "        \n",
    "        old = np.array([mu1, mu2, sigma1, sigma2, pi])\n",
    "        epsilon = np.linalg.norm(old - para)\n",
    "        mu1, mu2, sigma1, sigma2, pi = para\n",
    "\n",
    "    if mu1 + 1.96 * sigma1 < mu2 - 1.96 * sigma2:\n",
    "        if pi < out_cut:\n",
    "            return pd.Series(grp1_ind)\n",
    "        elif pi > 1 - out_cut:\n",
    "            return pd.Series(not_grp1_ind)\n",
    "    return pd.Series([False]*n)\n",
    "    \n",
    "\n",
    "def identify_outliers(feature_table, meta_data, group_var, out_cut):\n",
    "    z = feature_table + 1 # Add pseudo-count (1) # EEEE is this ok if data isn't counts?\n",
    "    f = z.apply(np.log)\n",
    "    f[f == 0] = np.nan # EEEE [sic]\n",
    "    f = f.mean(axis=0, skipna=True)\n",
    "    groups = meta_data[group_var]\n",
    "    groups.index = feature_table.columns\n",
    "    group_means = f.groupby(groups).mean()\n",
    "    notna_groups = pd.notna(groups)\n",
    "    group_means = group_means[groups[notna_groups].values]\n",
    "    group_means.index = groups[notna_groups].index\n",
    "    e = pd.Series([0]*f.size, index=f.index)\n",
    "    e[notna_groups] = f[notna_groups] - group_means\n",
    "    y = z - e\n",
    "\n",
    "    def row_outlier_check(row):\n",
    "        return row.groupby(groups).apply(\n",
    "            lambda x: _outlier_check(x, out_cut))\n",
    "    out_ind = y.apply(row_outlier_check, axis=1)\n",
    "    return np.array(out_ind)\n",
    "\n",
    "\n",
    "def identify_structure_zeros(\n",
    "    feature_table, meta_data, group_var, neg_lb):\n",
    "    group = meta_data[group_var]\n",
    "    group.index = feature_table.columns\n",
    "    present_table = feature_table.copy()\n",
    "    present_table[present_table.isna()] = 0\n",
    "    present_table[present_table != 0] = 1\n",
    "\n",
    "    p_hat = present_table.apply(\n",
    "        lambda row: row.groupby(group).mean(), axis=1)\n",
    "    samp_size = feature_table.apply(\n",
    "        lambda row: row.notna().groupby(group).sum(), axis=1)\n",
    "    p_hat_lo = p_hat - 1.96*np.sqrt(p_hat*(1 - p_hat)/samp_size)\n",
    "    \n",
    "    struc_zero = (p_hat == 0)*1\n",
    "    # Whether we need to classify a taxon into structural zero by its negative lower bound?\n",
    "    if neg_lb:\n",
    "        struc_zero[p_hat_lo <= 0] = 1\n",
    "    \n",
    "    # Entries considered to be structural zeros are set to be 0s\n",
    "    struc_ind = struc_zero[group]\n",
    "    struc_ind.columns = feature_table.columns\n",
    "    \n",
    "    struc_zero.columns = [\n",
    "            'structural_zero (' + c + ')' for c in struc_zero.columns]\n",
    "    \n",
    "    return struc_ind, struc_zero\n",
    "\n",
    "def feature_table_pre_process(\n",
    "    feature_table, meta_data, sample_var, group_var=None,\n",
    "    out_cut=0.05, zero_cut=0.9, lib_cut=1000, neg_lb=True\n",
    "):\n",
    "    # OTU table should be a pandas.DataFrame with each feature in rows and sample in columns.\n",
    "    # Metadata should be a pandas.DataFrame containing the sample identifier.\n",
    "    \n",
    "    # Drop unused levels\n",
    "    # meta_data[] = lapply(meta_data, function(x) if(is.factor(x)) factor(x) else x) # EEEE is this step necessary? Assuming \"no\" for now\n",
    "    \n",
    "    # Match sample IDs between metadata and feature table\n",
    "    sample_ID = meta_data[sample_var]\n",
    "    sample_ID = sample_ID[sample_ID.isin(feature_table.columns)]\n",
    "    feature_table = feature_table[sample_ID]\n",
    "    meta_data = meta_data[meta_data[sample_var].isin(sample_ID)]\n",
    "    \n",
    "    # 1. Identify outliers within each taxon\n",
    "    if (group_var is not None):\n",
    "        out_ind = identify_outliers(\n",
    "            feature_table, meta_data, group_var, out_cut)\n",
    "        feature_table[out_ind] = np.nan\n",
    "\n",
    "    # 2. Discard taxa with zeros  >=  zero_cut\n",
    "    zero_prop = feature_table.apply(\n",
    "        lambda x: (x==0).sum() / x.notna().sum(), axis=1)\n",
    "    feature_table = feature_table[zero_prop < zero_cut]\n",
    "    \n",
    "    # 3. Discard samples with library size < lib_cut\n",
    "    lib_size = feature_table.sum(axis=0, skipna=True)\n",
    "    feature_table = feature_table[\n",
    "        feature_table.columns[lib_size >= lib_cut]]\n",
    "    meta_data = meta_data[(lib_size >= lib_cut).values]\n",
    "\n",
    "    \n",
    "    # 4. Identify taxa with structure zeros\n",
    "    if (group_var is not None):\n",
    "        struc_ind, struc_zero = identify_structure_zeros(\n",
    "            feature_table, meta_data, group_var, neg_lb)\n",
    "        feature_table = feature_table * (1 - struc_ind)\n",
    "    else:\n",
    "        struc_zero = None\n",
    "        \n",
    "    return dict(\n",
    "        feature_table = feature_table,\n",
    "        meta_data = meta_data,\n",
    "        structure_zeros = struc_zero\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_identify_outliers():\n",
    "    feature_table = pd.read_csv(\"../data/ecam-table-taxa.tsv\",\n",
    "                           header=1, sep='\\t')\n",
    "    feature_table = feature_table.set_index('feature-id')\n",
    "    meta_data = pd.read_csv(\n",
    "        \"../data/ecam-sample-metadata.tsv\", sep='\\t')\n",
    "    meta_data = meta_data[1:]\n",
    "    meta_data = meta_data.rename(columns={'#SampleID': 'Sample.ID'})\n",
    "    \n",
    "    sample_ID = meta_data['Sample.ID']\n",
    "    sample_ID = sample_ID[sample_ID.isin(feature_table.columns)]\n",
    "    feature_table = feature_table[sample_ID]\n",
    "    meta_data = meta_data[meta_data['Sample.ID'].isin(sample_ID)]\n",
    "    \n",
    "    out_ind = identify_outliers(\n",
    "        feature_table, meta_data, 'delivery', 0.05)\n",
    "    answer = pd.read_csv('outliers.tsv', sep=' ', header=None)\n",
    "    assert np.all(out_ind == answer)\n",
    "\n",
    "\n",
    "def test_identify_structure_zeros():\n",
    "    feature_table = pd.read_csv(\"../data/ecam-table-taxa.tsv\",\n",
    "                           header=1, sep='\\t')\n",
    "    feature_table = feature_table.set_index('feature-id')\n",
    "    meta_data = pd.read_csv(\n",
    "        \"../data/ecam-sample-metadata.tsv\", sep='\\t')\n",
    "    meta_data = meta_data[1:]\n",
    "    meta_data = meta_data.rename(columns={'#SampleID': 'Sample.ID'})\n",
    "    \n",
    "    sample_ID = meta_data['Sample.ID']\n",
    "    sample_ID = sample_ID[sample_ID.isin(feature_table.columns)]\n",
    "    feature_table = feature_table[sample_ID]\n",
    "    meta_data = meta_data[meta_data['Sample.ID'].isin(sample_ID)]\n",
    "    \n",
    "    feature_table = pd.read_csv('feature-table.tsv', sep=' ')\n",
    "    struc_ind, struc_zero = identify_structure_zeros(\n",
    "            feature_table, meta_data, 'day_of_life', True)\n",
    "    answer = pd.read_csv('struc-zero.tsv', sep=' ')\n",
    "    answer.columns = [\n",
    "            'structural_zero (' + c + ')' for c in answer.columns]\n",
    "    assert np.all(struc_zero == answer)\n",
    "\n",
    "\n",
    "def test_feature_table_pre_process():\n",
    "    otu_data = pd.read_csv(\"../data/ecam-table-taxa.tsv\",\n",
    "                       header=1, sep='\\t')\n",
    "    otu_data = otu_data.set_index('feature-id')\n",
    "    \n",
    "    meta_data = pd.read_csv(\"../data/ecam-sample-metadata.tsv\", sep='\\t')\n",
    "    meta_data = meta_data[1:]\n",
    "    meta_data = meta_data.rename(columns={'#SampleID': 'Sample.ID'})\n",
    "    \n",
    "    result = feature_table_pre_process(\n",
    "        otu_data, meta_data, 'Sample.ID', 'delivery',\n",
    "        out_cut=0.05, zero_cut=0.9, lib_cut=0, neg_lb=True)\n",
    "    \n",
    "    answer = pd.read_csv('delivery-feature-table.tsv', sep=' ')\n",
    "    assert np.allclose(result['feature_table'], answer, equal_nan=True)\n",
    "    assert np.all(result['structure_zeros'] == 0)\n",
    "    assert np.all(meta_data == result['meta_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: overflow encountered in true_divide\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  del sys.path[0]\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: overflow encountered in true_divide\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "test_identify_outliers()\n",
    "test_identify_structure_zeros()\n",
    "test_feature_table_pre_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _p_function(main_var, meta_data, adj_formula, mixedlm_kwargs):\n",
    "    # Get a function to calcuate a p-value for each row using \n",
    "    # the appropriate model\n",
    "    if mixedlm_kwargs is None and adj_formula is None:\n",
    "        # Basic model\n",
    "        factors = set(meta_data[main_var])\n",
    "        indexes = [meta_data[main_var] == f for f in factors]\n",
    "        if len(factors) == 2:\n",
    "            # Two levels: Wilcoxon rank-sum test\n",
    "            def manwhittneyup(row):\n",
    "                # x = [row[ix[row.index]].dropna() for ix in indexes] this makes this work with swifter, but then swifter does nothing, so whatever\n",
    "                x = [row[ix].dropna() for ix in indexes]\n",
    "                u, p = mannwhitneyu(*x, alternative='two-sided')\n",
    "                return p\n",
    "            return manwhittneyup\n",
    "        # More than two levels: Kruskal-Wallis test\n",
    "        def kruskalp(row): # could be parallelised\n",
    "            x = [row[ix] for ix in indexes]\n",
    "            k, p = kruskal(*x, nan_policy='omit')\n",
    "            return p\n",
    "        return kruskalp\n",
    "    elif mixedlm_kwargs is None and adj_formula is not None:\n",
    "        # Model: ANOVA\n",
    "        formula = 'x ~ ' + main_var + ' + ' + adj_formula\n",
    "        def anovap(row):\n",
    "            row.name = 'x'\n",
    "            data = meta_data.join(row)\n",
    "            lm = ols(formula, data=data, missing='drop').fit()\n",
    "            anova = sm.stats.anova_lm(lm, typ=1) # to match R implemetation, consider changing to typ 2\n",
    "            return anova['PR(>F)'][main_var]\n",
    "        return anovap\n",
    "    # Model: Mixed-effects model\n",
    "    formula = 'x ~ ' + main_var\n",
    "    if adj_formula is not None:\n",
    "        formula += ' + ' + adj_formula\n",
    "    def mixedlmp(row):\n",
    "        row.name = 'x'\n",
    "        data = meta_data.join(row)\n",
    "        # print(formula)\n",
    "        # print(data)\n",
    "        # print(mixedlm_kwargs)\n",
    "        mdf = mixedlm(\n",
    "            formula, data, missing='drop', **mixedlm_kwargs).fit()\n",
    "        # print(mdf.summary())\n",
    "        # print(mdf.params.index)\n",
    "        f_test = mdf.f_test(\n",
    "            [p == main_var or p.startswith(main_var + '[')\n",
    "             for p in mdf.params.index])\n",
    "        # print(f_test)\n",
    "        return f_test.pvalue\n",
    "    return mixedlmp\n",
    "\n",
    "\n",
    "def get_p_values(\n",
    "    comp_table, meta_data, main_var, adj_formula, mixedlm_kwargs):\n",
    "    # Calculate the p-value for each pairwise comparison of taxa.\n",
    "    meta_data.index = comp_table.columns\n",
    "    calc_p = _p_function(\n",
    "        main_var, meta_data, adj_formula, mixedlm_kwargs)\n",
    "    \n",
    "    n_taxa = comp_table.shape[0]\n",
    "    p_data = np.empty([n_taxa, n_taxa])\n",
    "    p_data[:,:] = np.nan\n",
    "    for i in range(n_taxa - 1):\n",
    "        # Loop through each taxon.\n",
    "        # For each taxon i, additive log ratio (alr) transform the \n",
    "        # OTU table using taxon i as the reference.\n",
    "        # e.g. the first alr matrix will be the log abundance data \n",
    "        # (comp_table) recursively subtracted \n",
    "        # by the log abundance of 1st taxon (1st row) row-wisely,\n",
    "        # and remove the first i rows since:\n",
    "        # the first (i - 1) rows were calculated by previous\n",
    "        # iterations, and\n",
    "        # the i^th row contains all zeros.\n",
    "        alr_data = comp_table.sub(comp_table.iloc[i], axis=1)\n",
    "        # Here, we basically want to iteratively subtract each\n",
    "        # row of the comp_table by its i^th column.\n",
    "        alr_data = alr_data.iloc[i+1:]\n",
    "        p_data[i+1:, i] = alr_data.apply(calc_p, 1)\n",
    "    # Complete the p-value matrix.\n",
    "    # What we got from above iterations is a lower triangle matrix \n",
    "    # of p-values.\n",
    "    ix = np.logical_not(np.isnan(p_data.T))\n",
    "    p_data[ix] = p_data.T[ix] \n",
    "    # set p-values on diagonal equal to 1\n",
    "    p_data[np.eye(n_taxa, dtype=bool)] = 1\n",
    "    return pd.DataFrame(\n",
    "        p_data, index=comp_table.index, columns=comp_table.index)\n",
    "\n",
    "\n",
    "def ANCOM(feature_table, meta_data, main_var, struc_zero=None,\n",
    "          p_adj_method = 'fdr_bh', alpha=0.05, adj_formula=None,\n",
    "          mixedlm_kwargs=None):\n",
    "    # OTU table transformation: \n",
    "    # (1) Discard taxa with structural zeros (if any); \n",
    "    # (2) Add pseudocount (1) and take logarithm.\n",
    "    if struc_zero is not None:\n",
    "        num_struc_zero = struc_zero.apply(sum, axis=1)\n",
    "        comp_table = feature_table.loc[num_struc_zero == 0]\n",
    "    else:\n",
    "        comp_table = feature_table\n",
    "    comp_table = np.log(comp_table + 1)\n",
    "    \n",
    "    # Calculate the p-value for each pairwise comparison of taxa.\n",
    "    p_data = get_p_values(\n",
    "        comp_table, meta_data, main_var, adj_formula, mixedlm_kwargs)\n",
    "    \n",
    "    # Multiple comparisons correction.\n",
    "    q_data = p_data.apply(\n",
    "        lambda c: multipletests(c, method=p_adj_method)[1], axis=0)\n",
    "    \n",
    "    # Calculate the W statistic of ANCOM.\n",
    "    # For each taxon, count the number of q-values < alpha.\n",
    "    W = q_data.apply(lambda c: (c < alpha).sum(), axis=0)\n",
    "    \n",
    "    # Organize outputs\n",
    "    # Declare a taxon to be differentially abundant based on the \n",
    "    # quantile of W statistic.\n",
    "    # We perform (n_taxa - 1) hypothesis testings on each taxon, \n",
    "    # so the maximum number of rejections is (n_taxa - 1).\n",
    "    n_taxa = len(W)\n",
    "    out_comp = pd.DataFrame({\n",
    "        'W': W,\n",
    "        'detected_0.9': W > 0.9 * (n_taxa - 1),\n",
    "        'detected_0.8': W > 0.8 * (n_taxa - 1),\n",
    "        'detected_0.7': W > 0.7 * (n_taxa - 1),\n",
    "        'detected_0.6': W > 0.6 * (n_taxa - 1),\n",
    "    })\n",
    "    \n",
    "    # Taxa with structural zeros are automatically declared to\n",
    "    # be differentially abundant\n",
    "    if struc_zero is not None:\n",
    "        out_comp.loc[num_struc_zero != 0] = (np.inf,) + (True,)*4\n",
    "\n",
    "    return out_comp\n",
    "\n",
    "\n",
    "def clr(x):\n",
    "    tr = x.copy()\n",
    "    nz = tr[(tr != 0.) & tr.notna()]\n",
    "    nz = nz.apply(np.log)\n",
    "    nz -= nz.mean()\n",
    "    tr[(tr != 0.) & tr.notna()] = nz\n",
    "    return tr\n",
    "\n",
    "\n",
    "def ANCOM_volcano(feature_table, meta_data, main_var, W):\n",
    "    # Draw volcano plot\n",
    "    # Calculate clr\n",
    "    clr_table = feature_table.apply(clr, axis=0)\n",
    "    # Calculate clr mean difference\n",
    "    def mean_difference(y):\n",
    "        y.name = 'y'\n",
    "        data = meta_data.join(y)\n",
    "        formula = 'y ~ ' + main_var\n",
    "        lm = ols(formula, data=data).fit()\n",
    "        return lm.params[1:]\n",
    "    eff_size = clr_table.apply(mean_difference, axis=1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_p_values_manwhittneyu():\n",
    "    feature_table = pd.read_csv('delivery-feature-table.tsv', sep=' ')\n",
    "    meta_data = pd.read_csv(\"../data/ecam-sample-metadata.tsv\", sep='\\t')\n",
    "    meta_data = meta_data[1:]\n",
    "    meta_data = meta_data.rename(columns={'#SampleID': 'Sample.ID'})\n",
    "    comp_table = np.log(feature_table + 1)\n",
    "    \n",
    "    main_var = 'delivery'\n",
    "    adj_formula = None\n",
    "    mixedlm_kwargs = None\n",
    "    p_data = get_p_values(\n",
    "        comp_table, meta_data, main_var, adj_formula, mixedlm_kwargs)\n",
    "    \n",
    "    answer = pd.read_csv('p-values-manwhittneyu.tsv', sep=' ')\n",
    "    assert np.allclose(p_data, answer, rtol=1e-3)\n",
    "\n",
    "\n",
    "def test_get_p_values_kruskalp():\n",
    "    feature_table = pd.read_csv('delivery-feature-table.tsv', sep=' ')\n",
    "    meta_data = pd.read_csv(\"../data/ecam-sample-metadata.tsv\", sep='\\t')\n",
    "    meta_data = meta_data[1:]\n",
    "    meta_data = meta_data.rename(columns={'#SampleID': 'Sample.ID'})\n",
    "    comp_table = np.log(feature_table + 1)\n",
    "    \n",
    "    main_var = 'diet_3'\n",
    "    adj_formula = None\n",
    "    mixedlm_kwargs = None\n",
    "    p_data = get_p_values(\n",
    "        comp_table, meta_data, main_var, adj_formula, mixedlm_kwargs)\n",
    "    \n",
    "    answer = pd.read_csv('p-values-kruskalp.tsv', sep=' ')\n",
    "    assert np.allclose(p_data, answer)\n",
    "\n",
    "\n",
    "def test_get_p_values_anovap():\n",
    "    feature_table = pd.read_csv('delivery-feature-table.tsv', sep=' ')\n",
    "    meta_data = pd.read_csv(\"../data/ecam-sample-metadata.tsv\", sep='\\t')\n",
    "    meta_data = meta_data[1:]\n",
    "    meta_data = meta_data.rename(columns={'#SampleID': 'Sample.ID'})\n",
    "    comp_table = np.log(feature_table + 1)\n",
    "    \n",
    "    main_var = 'delivery'\n",
    "    adj_formula = 'studyid'\n",
    "    mixedlm_kwargs = None\n",
    "    p_data = get_p_values(\n",
    "        comp_table, meta_data, main_var, adj_formula, mixedlm_kwargs)\n",
    "    \n",
    "    answer = pd.read_csv('p-values-anovap.tsv', sep=' ')\n",
    "    assert np.allclose(p_data, answer)\n",
    "    \n",
    "\n",
    "def test_get_p_values_mixedlmp():\n",
    "    feature_table = pd.read_csv('delivery-feature-table.tsv', sep=' ')\n",
    "    meta_data = pd.read_csv(\"../data/ecam-sample-metadata.tsv\", sep='\\t')\n",
    "    meta_data = meta_data[1:]\n",
    "    meta_data = meta_data.rename(columns={'#SampleID': 'Sample.ID'})\n",
    "    comp_table = np.log(feature_table + 1)\n",
    "    \n",
    "    main_var = 'delivery'\n",
    "    adj_formula = None\n",
    "    mixedlm_kwargs = {'groups': meta_data['studyid']}\n",
    "    p_data = get_p_values(\n",
    "        comp_table, meta_data, main_var, adj_formula, mixedlm_kwargs)\n",
    "    \n",
    "    answer = pd.read_csv('p-values-mixedlmp.tsv', sep=' ')\n",
    "    assert np.allclose(p_data, answer, rtol=0.2, atol=0.03)\n",
    "    \n",
    "\n",
    "def test_ANCOM():\n",
    "    feature_table = pd.read_csv('delivery-feature-table.tsv', sep=' ')\n",
    "    meta_data = pd.read_csv(\"../data/ecam-sample-metadata.tsv\", sep='\\t')\n",
    "    meta_data = meta_data[1:]\n",
    "    meta_data = meta_data.rename(columns={'#SampleID': 'Sample.ID'})\n",
    "    comp_table = np.log(feature_table + 1)\n",
    "    \n",
    "    main_var = 'diet_3'\n",
    "    adj_formula = None\n",
    "    mixedlm_kwargs = None\n",
    "    p_adj_method = \"fdr_bh\"\n",
    "    alpha = 0.05\n",
    "    W = ANCOM(\n",
    "        feature_table, meta_data, main_var,struc_zero, p_adj_method, \n",
    "        alpha, adj_formula, mixedlm_kwargs)\n",
    "    \n",
    "    answer = pd.read_csv('ancom-w.tsv', sep=' ')\n",
    "    assert np.allclose(W['W'], answer['W'])\n",
    "    assert (np.array(answer.iloc[:,2:]) \n",
    "            == np.array(W.iloc[:,1:])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_get_p_values_manwhittneyu()\n",
    "test_get_p_values_kruskalp()\n",
    "test_get_p_values_anovap()\n",
    "test_get_p_values_mixedlmp() # go get a cup of tea\n",
    "test_ANCOM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: overflow encountered in true_divide\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data preprocessing\n",
    "\n",
    "feature_table = otu_data\n",
    "sample_var = \"Sample.ID\"\n",
    "group_var = \"delivery\"\n",
    "out_cut = 0.05\n",
    "zero_cut = 0.90\n",
    "lib_cut = 0\n",
    "neg_lb = True\n",
    "prepro = feature_table_pre_process(\n",
    "    feature_table, meta_data, sample_var, group_var, \n",
    "    out_cut, zero_cut, lib_cut, neg_lb)\n",
    "feature_table = prepro['feature_table'] # Preprocessed feature table\n",
    "meta_data = prepro['meta_data'] # Preprocessed metadata\n",
    "struc_zero = prepro['structure_zeros'] # Structural zero info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 2: ANCOM\n",
    "\n",
    "main_var = \"delivery\"\n",
    "p_adj_method = \"fdr_bh\"\n",
    "alpha = 0.05\n",
    "adj_formula = None\n",
    "#mixedlm_kwargs = {'groups': meta_data['studyid']}\n",
    "mixedlm_kwargs = None\n",
    "W = ANCOM(\n",
    "    feature_table, meta_data, main_var,struc_zero, p_adj_method, \n",
    "    alpha, adj_formula, mixedlm_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delivery[T.Vaginal]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature-id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;__;__;__;__;__</th>\n",
       "      <td>-0.207527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Actinobacteria;c__Actinobacteria;o__Actinomycetales;f__Actinomycetaceae;g__Actinomyces</th>\n",
       "      <td>0.238622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Actinobacteria;c__Actinobacteria;o__Actinomycetales;f__Micrococcaceae;g__Rothia</th>\n",
       "      <td>0.133285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Actinobacteria;c__Actinobacteria;o__Bifidobacteriales;f__Bifidobacteriaceae;g__Bifidobacterium</th>\n",
       "      <td>0.816852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Actinobacteria;c__Coriobacteriia;o__Coriobacteriales;f__Coriobacteriaceae;g__Collinsella</th>\n",
       "      <td>-0.123329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__Bacteroidaceae;g__Bacteroides</th>\n",
       "      <td>1.966017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__Porphyromonadaceae;g__Parabacteroides</th>\n",
       "      <td>0.704957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__Prevotellaceae;g__Prevotella</th>\n",
       "      <td>-0.266803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__Rikenellaceae;g__</th>\n",
       "      <td>0.013308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Bacilli;o__Bacillales;f__Staphylococcaceae;g__Staphylococcus</th>\n",
       "      <td>0.011812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Bacilli;o__Lactobacillales;f__Enterococcaceae;g__Enterococcus</th>\n",
       "      <td>-0.021847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Bacilli;o__Lactobacillales;f__Lactobacillaceae;g__Lactobacillus</th>\n",
       "      <td>-0.031145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Bacilli;o__Lactobacillales;f__Streptococcaceae;g__Streptococcus</th>\n",
       "      <td>-0.081965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Bacilli;o__Turicibacterales;f__Turicibacteraceae;g__Turicibacter</th>\n",
       "      <td>-0.078463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;__;__</th>\n",
       "      <td>-0.200511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__;g__</th>\n",
       "      <td>-0.262525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Clostridiaceae;__</th>\n",
       "      <td>-0.210629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Clostridiaceae;g__</th>\n",
       "      <td>-0.031036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Clostridiaceae;g__Clostridium</th>\n",
       "      <td>-0.640533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae;__</th>\n",
       "      <td>-0.135298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae;g__</th>\n",
       "      <td>-0.234578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae;g__Blautia</th>\n",
       "      <td>0.058283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae;g__Coprococcus</th>\n",
       "      <td>0.195692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae;g__Dorea</th>\n",
       "      <td>-0.211387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae;g__Lachnospira</th>\n",
       "      <td>0.264900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae;g__Roseburia</th>\n",
       "      <td>-0.101290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae;g__[Ruminococcus]</th>\n",
       "      <td>-0.422805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Peptostreptococcaceae;g__</th>\n",
       "      <td>-0.294452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Ruminococcaceae;__</th>\n",
       "      <td>0.107667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Ruminococcaceae;g__</th>\n",
       "      <td>0.298415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Ruminococcaceae;g__Faecalibacterium</th>\n",
       "      <td>0.496312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Ruminococcaceae;g__Oscillospira</th>\n",
       "      <td>-0.159949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Ruminococcaceae;g__Ruminococcus</th>\n",
       "      <td>0.001712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Veillonellaceae;g__Dialister</th>\n",
       "      <td>-0.041058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Veillonellaceae;g__Phascolarctobacterium</th>\n",
       "      <td>-0.083742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Veillonellaceae;g__Veillonella</th>\n",
       "      <td>-0.476293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Erysipelotrichi;o__Erysipelotrichales;f__Erysipelotrichaceae;g__</th>\n",
       "      <td>-0.330495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Erysipelotrichi;o__Erysipelotrichales;f__Erysipelotrichaceae;g__Coprobacillus</th>\n",
       "      <td>0.126579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Firmicutes;c__Erysipelotrichi;o__Erysipelotrichales;f__Erysipelotrichaceae;g__[Eubacterium]</th>\n",
       "      <td>-0.298728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Fusobacteria;c__Fusobacteriia;o__Fusobacteriales;f__Fusobacteriaceae;g__Fusobacterium</th>\n",
       "      <td>0.153348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Proteobacteria;c__Betaproteobacteria;o__Burkholderiales;f__Alcaligenaceae;g__Sutterella</th>\n",
       "      <td>0.241047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Proteobacteria;c__Deltaproteobacteria;o__Desulfovibrionales;f__Desulfovibrionaceae;g__Bilophila</th>\n",
       "      <td>-0.156808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Proteobacteria;c__Gammaproteobacteria;o__Enterobacteriales;f__Enterobacteriaceae;__</th>\n",
       "      <td>-0.768700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Proteobacteria;c__Gammaproteobacteria;o__Enterobacteriales;f__Enterobacteriaceae;g__</th>\n",
       "      <td>-0.204937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Proteobacteria;c__Gammaproteobacteria;o__Pasteurellales;f__Pasteurellaceae;g__Haemophilus</th>\n",
       "      <td>0.086089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Proteobacteria;c__Gammaproteobacteria;o__Pseudomonadales;f__Moraxellaceae;g__Acinetobacter</th>\n",
       "      <td>0.138782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Proteobacteria;c__Gammaproteobacteria;o__Pseudomonadales;f__Pseudomonadaceae;g__Pseudomonas</th>\n",
       "      <td>-0.082500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k__Bacteria;p__Verrucomicrobia;c__Verrucomicrobiae;o__Verrucomicrobiales;f__Verrucomicrobiaceae;g__Akkermansia</th>\n",
       "      <td>0.115565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    delivery[T.Vaginal]\n",
       "feature-id                                                             \n",
       "k__Bacteria;__;__;__;__;__                                    -0.207527\n",
       "k__Bacteria;p__Actinobacteria;c__Actinobacteria...             0.238622\n",
       "k__Bacteria;p__Actinobacteria;c__Actinobacteria...             0.133285\n",
       "k__Bacteria;p__Actinobacteria;c__Actinobacteria...             0.816852\n",
       "k__Bacteria;p__Actinobacteria;c__Coriobacteriia...            -0.123329\n",
       "k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__...             1.966017\n",
       "k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__...             0.704957\n",
       "k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__...            -0.266803\n",
       "k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__...             0.013308\n",
       "k__Bacteria;p__Firmicutes;c__Bacilli;o__Bacilla...             0.011812\n",
       "k__Bacteria;p__Firmicutes;c__Bacilli;o__Lactoba...            -0.021847\n",
       "k__Bacteria;p__Firmicutes;c__Bacilli;o__Lactoba...            -0.031145\n",
       "k__Bacteria;p__Firmicutes;c__Bacilli;o__Lactoba...            -0.081965\n",
       "k__Bacteria;p__Firmicutes;c__Bacilli;o__Turicib...            -0.078463\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...            -0.200511\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...            -0.262525\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...            -0.210629\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...            -0.031036\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...            -0.640533\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...            -0.135298\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...            -0.234578\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...             0.058283\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...             0.195692\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...            -0.211387\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...             0.264900\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...            -0.101290\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...            -0.422805\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...            -0.294452\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...             0.107667\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...             0.298415\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...             0.496312\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...            -0.159949\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...             0.001712\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...            -0.041058\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...            -0.083742\n",
       "k__Bacteria;p__Firmicutes;c__Clostridia;o__Clos...            -0.476293\n",
       "k__Bacteria;p__Firmicutes;c__Erysipelotrichi;o_...            -0.330495\n",
       "k__Bacteria;p__Firmicutes;c__Erysipelotrichi;o_...             0.126579\n",
       "k__Bacteria;p__Firmicutes;c__Erysipelotrichi;o_...            -0.298728\n",
       "k__Bacteria;p__Fusobacteria;c__Fusobacteriia;o_...             0.153348\n",
       "k__Bacteria;p__Proteobacteria;c__Betaproteobact...             0.241047\n",
       "k__Bacteria;p__Proteobacteria;c__Deltaproteobac...            -0.156808\n",
       "k__Bacteria;p__Proteobacteria;c__Gammaproteobac...            -0.768700\n",
       "k__Bacteria;p__Proteobacteria;c__Gammaproteobac...            -0.204937\n",
       "k__Bacteria;p__Proteobacteria;c__Gammaproteobac...             0.086089\n",
       "k__Bacteria;p__Proteobacteria;c__Gammaproteobac...             0.138782\n",
       "k__Bacteria;p__Proteobacteria;c__Gammaproteobac...            -0.082500\n",
       "k__Bacteria;p__Verrucomicrobia;c__Verrucomicrob...             0.115565"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = ANCOM_volcano(feature_table, meta_data, main_var, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
