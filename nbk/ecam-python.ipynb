{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "otu_data = pd.read_csv(\"../data/ecam-table-taxa.tsv\",\n",
    "                       header=1, sep='\\t')\n",
    "otu_data = otu_data.set_index('feature-id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.read_csv(\"../data/ecam-sample-metadata.tsv\", sep='\\t')\n",
    "meta_data = meta_data[1:]\n",
    "meta_data = meta_data.rename(columns={'#SampleID': 'Sample.ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANCOM imports\n",
    "import numpy as np\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _outlier_check(x, out_cut):\n",
    "    # Fitting the mixture model using the algorithm of Peddada, S. Das, and JT Gene Hwang (2002)\n",
    "    mu1, mu2 = np.nanquantile(x, (0.25, 0.75))\n",
    "    sigma1 = mu2 - mu1\n",
    "    sigma2 = sigma1\n",
    "    pi = 0.75\n",
    "    n = len(x)\n",
    "    epsilon = 100\n",
    "    tol = 1e-5\n",
    "    score = pi * norm.pdf(x, mu1, sigma1) / \\\n",
    "        ((1 - pi) * norm.pdf(x, mu2, sigma2))\n",
    "    while epsilon > tol:\n",
    "        grp1_ind = score >= 1\n",
    "        not_grp1_ind = np.logical_not(grp1_ind)\n",
    "        mu1_new = x[grp1_ind].mean()\n",
    "        mu2_new = x[not_grp1_ind].mean()\n",
    "        sigma1_new = x[grp1_ind].std()\n",
    "        if np.isnan(sigma1_new):\n",
    "            sigma1_new = 0.\n",
    "        sigma2_new = x[not_grp1_ind].std()\n",
    "        if np.isnan(sigma2_new):\n",
    "            sigma2_new = 0.\n",
    "        pi_new = sum(grp1_ind) / n\n",
    "        \n",
    "        para = [mu1_new, mu2_new, sigma1_new, sigma2_new, pi_new]\n",
    "        if np.any(np.isnan(para)):\n",
    "            break\n",
    "        \n",
    "        if sigma1_new == 0.:\n",
    "            pdf1 = np.zeros_like(x)\n",
    "            pdf1[x == mu1_new] = np.inf\n",
    "        else:\n",
    "            pdf1 = norm.pdf(x, mu1_new, sigma1_new)\n",
    "        if sigma2_new == 0.:\n",
    "            pdf2 = np.zeros_like(x)\n",
    "            pdf2[x == mu2_new] = np.inf\n",
    "        else:\n",
    "            pdf2 = norm.pdf(x, mu2_new, sigma2_new)\n",
    "        score = pi_new * pdf1 / ((1 - pi_new) * pdf2)\n",
    "        \n",
    "        old = np.array([mu1, mu2, sigma1, sigma2, pi])\n",
    "        epsilon = np.linalg.norm(old - para)\n",
    "        mu1, mu2, sigma1, sigma2, pi = para\n",
    "\n",
    "    if mu1 + 1.96 * sigma1 < mu2 - 1.96 * sigma2:\n",
    "        if pi < out_cut:\n",
    "            return pd.Series(grp1_ind)\n",
    "        elif pi > 1 - out_cut:\n",
    "            return pd.Series(not_grp1_ind)\n",
    "    return pd.Series([False]*n)\n",
    "    \n",
    "\n",
    "def identify_outliers(feature_table, meta_data, group_var, out_cut):\n",
    "    z = feature_table + 1 # Add pseudo-count (1) # EEEE is this ok if data isn't counts?\n",
    "    f = z.apply(np.log)\n",
    "    f[f == 0] = np.nan # EEEE [sic]\n",
    "    f = f.mean(axis=0, skipna=True)\n",
    "    groups = meta_data[group_var]\n",
    "    groups.index = feature_table.columns\n",
    "    group_means = f.groupby(groups).mean()\n",
    "    notna_groups = pd.notna(groups)\n",
    "    group_means = group_means[groups[notna_groups].values]\n",
    "    group_means.index = groups[notna_groups].index\n",
    "    e = pd.Series([0]*f.size, index=f.index)\n",
    "    e[notna_groups] = f[notna_groups] - group_means\n",
    "    y = z - e\n",
    "\n",
    "    def row_outlier_check(row):\n",
    "        return row.groupby(groups).apply(\n",
    "            lambda x: _outlier_check(x, out_cut))\n",
    "    out_ind = y.apply(row_outlier_check, axis=1)\n",
    "    return np.array(out_ind)\n",
    "\n",
    "\n",
    "def identify_structure_zeros(\n",
    "    feature_table, meta_data, group_var, neg_lb):\n",
    "    group = meta_data[group_var]\n",
    "    group.index = feature_table.columns\n",
    "    present_table = feature_table.copy()\n",
    "    present_table[present_table.isna()] = 0\n",
    "    present_table[present_table != 0] = 1\n",
    "\n",
    "    p_hat = present_table.apply(\n",
    "        lambda row: row.groupby(group).mean(), axis=1)\n",
    "    samp_size = feature_table.apply(\n",
    "        lambda row: row.notna().groupby(group).sum(), axis=1)\n",
    "    p_hat_lo = p_hat - 1.96*np.sqrt(p_hat*(1 - p_hat)/samp_size)\n",
    "    \n",
    "    struc_zero = (p_hat == 0)*1\n",
    "    # Whether we need to classify a taxon into structural zero by its negative lower bound?\n",
    "    if neg_lb:\n",
    "        struc_zero[p_hat_lo <= 0] = 1\n",
    "    \n",
    "    # Entries considered to be structural zeros are set to be 0s\n",
    "    struc_ind = struc_zero[group]\n",
    "    struc_ind.columns = feature_table.columns\n",
    "    \n",
    "    struc_zero.columns = [\n",
    "            'structural_zero (' + c + ')' for c in struc_zero.columns]\n",
    "    \n",
    "    return struc_ind, struc_zero\n",
    "\n",
    "def feature_table_pre_process(\n",
    "    feature_table, meta_data, sample_var, group_var=None,\n",
    "    out_cut=0.05, zero_cut=0.9, lib_cut=1000, neg_lb=True\n",
    "):\n",
    "    # OTU table should be a pandas.DataFrame with each feature in rows and sample in columns.\n",
    "    # Metadata should be a pandas.DataFrame containing the sample identifier.\n",
    "    \n",
    "    # Drop unused levels\n",
    "    # meta_data[] = lapply(meta_data, function(x) if(is.factor(x)) factor(x) else x) # EEEE is this step necessary? Assuming \"no\" for now\n",
    "    \n",
    "    # Match sample IDs between metadata and feature table\n",
    "    sample_ID = meta_data[sample_var]\n",
    "    sample_ID = sample_ID[sample_ID.isin(feature_table.columns)]\n",
    "    feature_table = feature_table[sample_ID]\n",
    "    meta_data = meta_data[meta_data[sample_var].isin(sample_ID)]\n",
    "    \n",
    "    # 1. Identify outliers within each taxon\n",
    "    if (group_var is not None):\n",
    "        out_ind = identify_outliers(\n",
    "            feature_table, meta_data, group_var, out_cut)\n",
    "        feature_table[out_ind] = np.nan\n",
    "\n",
    "    # 2. Discard taxa with zeros  >=  zero_cut\n",
    "    zero_prop = feature_table.apply(\n",
    "        lambda x: (x==0).sum() / x.notna().sum(), axis=1)\n",
    "    feature_table = feature_table[zero_prop < zero_cut]\n",
    "    \n",
    "    # 3. Discard samples with library size < lib_cut\n",
    "    lib_size = feature_table.sum(axis=0, skipna=True)\n",
    "    feature_table = feature_table[\n",
    "        feature_table.columns[lib_size >= lib_cut]]\n",
    "    meta_data = meta_data[(lib_size >= lib_cut).values]\n",
    "\n",
    "    \n",
    "    # 4. Identify taxa with structure zeros\n",
    "    if (group_var is not None):\n",
    "        struc_ind, struc_zero = identify_structure_zeros(\n",
    "            feature_table, meta_data, group_var, neg_lb)\n",
    "        feature_table = feature_table * (1 - struc_ind)\n",
    "    else:\n",
    "        struc_zero = None\n",
    "        \n",
    "    return dict(\n",
    "        feature_table = feature_table,\n",
    "        meta_data = meta_data,\n",
    "        structure_zeros = struc_zero\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_identify_outliers():\n",
    "    feature_table = pd.read_csv(\"../data/ecam-table-taxa.tsv\",\n",
    "                           header=1, sep='\\t')\n",
    "    feature_table = feature_table.set_index('feature-id')\n",
    "    meta_data = pd.read_csv(\n",
    "        \"../data/ecam-sample-metadata.tsv\", sep='\\t')\n",
    "    meta_data = meta_data[1:]\n",
    "    meta_data = meta_data.rename(columns={'#SampleID': 'Sample.ID'})\n",
    "    \n",
    "    sample_ID = meta_data['Sample.ID']\n",
    "    sample_ID = sample_ID[sample_ID.isin(feature_table.columns)]\n",
    "    feature_table = feature_table[sample_ID]\n",
    "    meta_data = meta_data[meta_data['Sample.ID'].isin(sample_ID)]\n",
    "    \n",
    "    out_ind = identify_outliers(\n",
    "        feature_table, meta_data, 'delivery', 0.05)\n",
    "    answer = pd.read_csv('outliers.tsv', sep=' ', header=None)\n",
    "    assert np.all(out_ind == answer)\n",
    "    \n",
    "def test_identify_structure_zeros():\n",
    "    feature_table = pd.read_csv(\"../data/ecam-table-taxa.tsv\",\n",
    "                           header=1, sep='\\t')\n",
    "    feature_table = feature_table.set_index('feature-id')\n",
    "    meta_data = pd.read_csv(\n",
    "        \"../data/ecam-sample-metadata.tsv\", sep='\\t')\n",
    "    meta_data = meta_data[1:]\n",
    "    meta_data = meta_data.rename(columns={'#SampleID': 'Sample.ID'})\n",
    "    \n",
    "    sample_ID = meta_data['Sample.ID']\n",
    "    sample_ID = sample_ID[sample_ID.isin(feature_table.columns)]\n",
    "    feature_table = feature_table[sample_ID]\n",
    "    meta_data = meta_data[meta_data['Sample.ID'].isin(sample_ID)]\n",
    "    \n",
    "    feature_table = pd.read_csv('feature-table.tsv', sep=' ')\n",
    "    struc_ind, struc_zero = identify_structure_zeros(\n",
    "            feature_table, meta_data, 'day_of_life', True)\n",
    "    answer = pd.read_csv('struc-zero.tsv', sep=' ')\n",
    "    answer.columns = [\n",
    "            'structural_zero (' + c + ')' for c in answer.columns]\n",
    "    assert np.all(struc_zero == answer)\n",
    "    \n",
    "def test_feature_table_pre_process():\n",
    "    otu_data = pd.read_csv(\"../data/ecam-table-taxa.tsv\",\n",
    "                       header=1, sep='\\t')\n",
    "    otu_data = otu_data.set_index('feature-id')\n",
    "    \n",
    "    meta_data = pd.read_csv(\"../data/ecam-sample-metadata.tsv\", sep='\\t')\n",
    "    meta_data = meta_data[1:]\n",
    "    meta_data = meta_data.rename(columns={'#SampleID': 'Sample.ID'})\n",
    "    \n",
    "    result = feature_table_pre_process(\n",
    "        otu_data, meta_data, 'Sample.ID', 'delivery',\n",
    "        out_cut=0.05, zero_cut=0.9, lib_cut=0, neg_lb=True)\n",
    "    \n",
    "    answer = pd.read_csv('delivery-feature-table.tsv', sep=' ')\n",
    "    assert np.allclose(result['feature_table'], answer, equal_nan=True)\n",
    "    assert np.all(result['structure_zeros'] == 0)\n",
    "    assert np.all(meta_data == result['meta_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: overflow encountered in true_divide\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  del sys.path[0]\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: overflow encountered in true_divide\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/ben/miniconda3/envs/qiime2-2019.10/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "test_identify_outliers()\n",
    "test_identify_structure_zeros()\n",
    "test_feature_table_pre_process()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
